{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdbd878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alle packages\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b87f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read the CSV, parsing the DateTime column as datetime64\n",
    "df = pd.read_csv(\n",
    "    'historian.db.F5.03.csv',\n",
    "    parse_dates=['DateTime']        # ← this ensures df['DateTime'] is datetime64[ns]\n",
    ")\n",
    "\n",
    "# 2. Melt into long format\n",
    "trend = df.melt(\n",
    "    id_vars=['DateTime'],\n",
    "    var_name='asset',\n",
    "    value_name='valve_pos'\n",
    ")\n",
    "\n",
    "# 3. Clean up column names\n",
    "trend['asset'] = trend['asset'].str.replace(r'\\.Status$', '', regex=True)\n",
    "\n",
    "# 4. Rename columns to match your desired output\n",
    "trend.rename(columns={\n",
    "    'DateTime': 'dt', \n",
    "    'valve_pos': 'valve pos'\n",
    "}, inplace=True)\n",
    "\n",
    "# 5. (Optional) Display or save the result\n",
    "print(trend.head())\n",
    "# trend.to_csv('trend.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee93ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming df is your big or small DataFrame\n",
    "trend['asset'] = trend['asset'].str[-3:].astype(int) - 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fc38f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trend.sort_values(by = 'dt').head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5511b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alarm_dataframe(filepath: str = 'alarm.viewer.F5.03.xlsx') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads an Excel file of alarms, parses TagName into Tag and Alarm,\n",
    "    and returns a DataFrame with DateTime, Tag and Alarm columns.\n",
    "    \"\"\"\n",
    "    # Read in the Excel file\n",
    "    df = pd.read_excel(filepath, engine='openpyxl')\n",
    "\n",
    "    \n",
    "    # Ensure DateTime is a datetime dtype\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "    \n",
    "    # Split TagName into three parts: prefix1, prefix2, and alarm name\n",
    "    parts = df['TagName'].str.split('.', n=2, expand=True)\n",
    "    \n",
    "    # Recombine first two parts for Tag and take the third part as Alarm\n",
    "    df['Tag']   = parts[0] + '.' + parts[1]\n",
    "    df['Alarm'] = parts[2]\n",
    "    \n",
    "    # Return only the columns you care about\n",
    "    return df[['DateTime','Tag','Alarm']]\n",
    "    \n",
    "\n",
    "# --- usage elsewhere in your code ---\n",
    "alarm_df = load_alarm_dataframe()   # now `alarm_df` holds your processed data\n",
    "\n",
    "alarm_df.rename(columns={'DateTime': 'dt'}, inplace=True)\n",
    "\n",
    "# in-place overwrite:\n",
    "alarm_df['Tag'] = (\n",
    "    alarm_df['Tag']\n",
    "      .str.extract(r'(\\d{3})\\.PV$')[0]  # grab the \"001\"… \"012\"\n",
    "      .astype(int)                      # turn \"001\"→1, … \"012\"→12\n",
    ")\n",
    "\n",
    "\n",
    "# You can reuse `alarm_df` anytime later:\n",
    "print(alarm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2) Extract base Tag and map to asset in alarm_df ---\n",
    "#   e.g. \"313PT009.PV\" → \"313PT009\" → maps to \"313XV029\"\n",
    "alarm_df['asset'] = (\n",
    "    alarm_df['Tag']\n",
    ")\n",
    "\n",
    "# --- 3) Normalize both DataFrames: dt → DateTime, parse, sort by asset & time ---\n",
    "def prep(df):\n",
    "    # drop any duplicate columns\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "    # rename 'dt' → 'DateTime'\n",
    "    if 'dt' in df.columns:\n",
    "        df = df.rename(columns={'dt':'DateTime'})\n",
    "    # ensure DateTime exists\n",
    "    if 'DateTime' not in df.columns:\n",
    "        raise KeyError(f\"'DateTime' not found in {df.columns.tolist()}\")\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "    return df\n",
    "\n",
    "trend    = prep(trend)\n",
    "alarm_df = prep(alarm_df)\n",
    "\n",
    "trend    = trend   .sort_values(['asset','DateTime']).reset_index(drop=True)\n",
    "alarm_df = alarm_df.sort_values(['asset','DateTime']).reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e866f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ensure DateTime is datetime, and asset_id is int in both tables\n",
    "for df in (trend, alarm_df):\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "    df['asset'] = df['asset'].astype(int)\n",
    "\n",
    "# helper to asof-merge one asset's worth of rows\n",
    "def asof_for_asset(asset, trend_grp):\n",
    "    # take only the alarm rows for this asset\n",
    "    alarms = alarm_df[alarm_df['asset'] == asset]\n",
    "    # both must be sorted by time for merge_asof\n",
    "    trend_grp = trend_grp.sort_values('DateTime')\n",
    "    alarms    = alarms.sort_values('DateTime')\n",
    "    # merge—the last alarm at or before each trend timestamp\n",
    "    return pd.merge_asof(\n",
    "        trend_grp,\n",
    "        alarms,\n",
    "        on='DateTime',\n",
    "        direction='backward',\n",
    "        suffixes=('','_alarm')\n",
    "    )\n",
    "\n",
    "# apply per-asset and reassemble\n",
    "merged = (\n",
    "    trend\n",
    "      .groupby('asset', group_keys=False)\n",
    "      .apply(lambda grp: asof_for_asset(grp.name, grp))\n",
    "      .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f22f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.count(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c712a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(\n",
    "    trend,\n",
    "    alarm_df,\n",
    "    on=['DateTime','asset'],\n",
    "    how='left'          # ← keeps every row from big_df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c59484",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = merged.count()\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2505eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make sure your DataFrame is sorted by time\n",
    "merged = merged.sort_values('DateTime')\n",
    "\n",
    "# 2. Mark the times when an alarm appears\n",
    "#    We’ll create a helper column that is the timestamp when alarm is non-empty,\n",
    "#    and NaT everywhere else.\n",
    "merged['alarm_time'] = merged['DateTime'].where(merged['Alarm'].notna() & (merged['Alarm'].str.strip() != ''))\n",
    "\n",
    "# 3. Propagate (forward-fill) that timestamp to subsequent rows\n",
    "merged['alarm_time'] = merged['alarm_time'].ffill()\n",
    "\n",
    "# 4. Compute flag: 1 if current row is within 5 seconds of the last alarm_time\n",
    "merged['alarm_flag'] = (\n",
    "    (merged['DateTime'] - merged['alarm_time']) <= pd.Timedelta(seconds=5)\n",
    ").fillna(False).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6989b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make sure your rows are in chronological order\n",
    "merged = merged.sort_values(['asset','DateTime']).reset_index(drop=True)\n",
    "\n",
    "# 2. Prepare the output column and a little “state” variable\n",
    "merged['failure_period'] = 0\n",
    "in_failure = 0\n",
    "\n",
    "# 3. Walk through each row and update the state\n",
    "for i, row in merged.iterrows():\n",
    "    # if we’re not in a failure, check for the start condition\n",
    "    if in_failure == 0 and row['alarm_flag'] == 1 and row['valve pos'] == 1:\n",
    "        in_failure = 1\n",
    "    # if we are in a failure, check for the stop condition\n",
    "    elif in_failure == 1 and row['valve pos'] == 2:\n",
    "        in_failure = 0\n",
    "\n",
    "    # write the current state into the new column\n",
    "    merged.at[i, 'failure_period'] = in_failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659c6523",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save without the index column\n",
    "merged.to_csv('merged_with_alarm_flag.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745df9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = merged.count()\n",
    "print(counts)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
